{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1f2881-7273-45ff-9259-537b23ad8ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: /Users/alexanderdahm/Documents/GitHub/mlfs-book-proj\n",
      "Added the following directory to the PYTHONPATH: /Users/alexanderdahm/Documents/GitHub/mlfs-book-proj\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a80c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f447120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:31:22,074 WARNING: DeprecationWarning: 'parseString' deprecated - use 'parse_string'\n",
      "\n",
      "2025-12-27 16:31:22,074 WARNING: DeprecationWarning: 'resetCache' deprecated - use 'reset_cache'\n",
      "\n",
      "2025-12-27 16:31:22,103 WARNING: DeprecationWarning: 'enablePackrat' deprecated - use 'enable_packrat'\n",
      "\n",
      "2025-12-27 16:31:22,118 WARNING: In /Users/alexanderdahm/miniconda3/envs/aq/lib/python3.10/site-packages/matplotlib/mpl-data/stylelib/classic.mplstyle: 'parseString' deprecated - use 'parse_string'\n",
      "2025-12-27 16:31:22,118 WARNING: In /Users/alexanderdahm/miniconda3/envs/aq/lib/python3.10/site-packages/matplotlib/mpl-data/stylelib/classic.mplstyle: 'resetCache' deprecated - use 'reset_cache'\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50156f96",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1a49d6-9cd2-4246-b0ca-1058672e4848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:31:22,242 INFO: Initializing external client\n",
      "2025-12-27 16:31:22,242 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:31:23,771 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1290388\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8fcaa1-dc14-48bf-b39d-c586d3da9544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully found at the path: /Users/alexanderdahm/Documents/GitHub/mlfs-book-proj/data/Day-ahead_SE2_SEK_2023-2025ytd.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "today = datetime.date.today()\n",
    "csv_file=f\"{root_dir}/data/Day-ahead_SE2_SEK_2023-2025ytd.csv\"\n",
    "util.check_file_path(csv_file)\n",
    "\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# If this API call fails (it fails in a github action), then set longitude and latitude explicitly - comment out next line\n",
    "#latitude, longitude = util.get_city_coordinates(city)\n",
    "# Uncomment this if API call to get longitude and latitude\n",
    "# latitude = sensorList[i].lat\n",
    "# longitude = sensorList[i].lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e751",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 5: Read your CSV file into a DataFrame </span>\n",
    "\n",
    "The cell below will read up historical air quality data as a CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3a1212",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    datetime64[ns]\n",
      "sek            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file,  parse_dates=['date'], skipinitialspace=True, sep=';', decimal=',')\n",
    "df\n",
    "df['sek'] = (\n",
    "    df['sek']\n",
    "      .astype(str)\n",
    "      .str.replace(' ', '', regex=False)   # remove spaces\n",
    "      .str.replace(',', '.', regex=False)  # decimal comma ‚Üí dot\n",
    "      .astype(float)                       # convert to float\n",
    ")\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812eb37-04e3-4291-8d77-a69ef7a195bc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 6: Data cleaning</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcfa73",
   "metadata": {},
   "source": [
    "## Check the data types for the columns in your DataFrame\n",
    "\n",
    " * `date` should be of type   datetime64[ns] \n",
    " * `pm25` should be of type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd20c859-ef3c-4b54-bbcb-83898afefa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    datetime64[ns]\n",
       "sek            float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq = df[['date', 'sek']]\n",
    "\n",
    "df_aq['sek'] = df_aq['sek'].astype('float32')\n",
    "df_aq\n",
    "df_aq.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f13a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1089 entries, 0 to 1088\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    1089 non-null   datetime64[ns]\n",
      " 1   sek     1089 non-null   float32       \n",
      "dtypes: datetime64[ns](1), float32(1)\n",
      "memory usage: 12.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Cast the pm25 column to be a float32 data type\n",
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19911f73",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 7: Drop any rows with missing data </span>\n",
    "It will make the model training easier if there is no missing data in the rows, so we drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b0a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    datetime64[ns]\n",
       "sek            float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq.dropna(inplace=True)\n",
    "\n",
    "df_aq = df_aq.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "#df_aq[\"pm25_roll3\"] = df_aq[\"pm25\"].shift(1).rolling(window=3).mean()\n",
    "\n",
    "#df_aq = df_aq.dropna(subset=[\"pm25_roll3\"])\n",
    "\n",
    "df_aq.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d3cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    datetime64[ns]\n",
       "sek            float32\n",
       "zone            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq['zone'] = \"SE2\"\n",
    "df_aq\n",
    "df_aq.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6dc05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1089 entries, 0 to 1088\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    1089 non-null   datetime64[ns]\n",
      " 1   sek     1089 non-null   float32       \n",
      " 2   zone    1089 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(1)\n",
      "memory usage: 21.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8276",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78686a28",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 9: Download the Historical Weather Data </span>\n",
    "Load weather data from 5 different cities located in our energy zone. Then concat all values into a single dataframe. There will therefore be 5 distinct weather values on each date.\n",
    "\n",
    "The weather features we will download are:\n",
    "\n",
    " * `temperature (average over the day)`\n",
    " * `precipitation (the total over the day)`\n",
    " * `wind speed (average over the day)`\n",
    " * `wind direction (the most dominant direction over the day)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 62.74164962768555¬∞N 13.77550983428955¬∞E\n",
      "Elevation 478.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Coordinates 61.82776641845703¬∞N 17.11111068725586¬∞E\n",
      "Elevation 65.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Coordinates 62.53075408935547¬∞N 15.721518516540527¬∞E\n",
      "Elevation 165.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Coordinates 63.16344451904297¬∞N 17.25388526916504¬∞E\n",
      "Elevation 66.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Coordinates 63.866432189941406¬∞N 20.106382369995117¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date\n",
    "\n",
    "\n",
    "\n",
    "# 5 diffeten weather sensors\n",
    "cities = [\n",
    "    {\"name\": \"flasjon\", \"lat\": 62.760350390111626, \"lon\": 13.715986496712969},\n",
    "    {\"name\": \"hudiksvall\", \"lat\": 61.790862930411194, \"lon\": 17.15754858778168},\n",
    "    {\"name\": \"ange\", \"lat\": 62.54989082316923, \"lon\": 15.751547550392734},\n",
    "    {\"name\": \"solleftea\", \"lat\": 63.159587742988755, \"lon\": 17.2655114712721},\n",
    "    {\"name\": \"umea\", \"lat\": 63.81702480736613, \"lon\": 20.18691175826482},\n",
    "]\n",
    "\n",
    "# Store indivudal city data frames\n",
    "all_weather_data = []\n",
    "\n",
    "for city in cities:\n",
    "    weather_df = util.get_historical_weather(city[\"name\"], earliest_aq_date, str(today), city[\"lat\"], city[\"lon\"])\n",
    "    \n",
    "    # Rename columns to include city name\n",
    "    weather_df = weather_df.rename(columns={col: f\"{col}_{city['name']}\" for col in weather_df.columns if col != \"date\"})\n",
    "    \n",
    "    all_weather_data.append(weather_df)\n",
    "\n",
    "# Merge all dataframes on date\n",
    "combined_weather_df = all_weather_data[0]\n",
    "for df in all_weather_data[1:]:\n",
    "    combined_weather_df = pd.merge(combined_weather_df, df, on=\"date\", how=\"outer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1092 entries, 0 to 1091\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                  Non-Null Count  Dtype         \n",
      "---  ------                                  --------------  -----         \n",
      " 0   date                                    1092 non-null   datetime64[ns]\n",
      " 1   temperature_2m_mean_flasjon             1092 non-null   float32       \n",
      " 2   precipitation_sum_flasjon               1092 non-null   float32       \n",
      " 3   wind_speed_10m_max_flasjon              1092 non-null   float32       \n",
      " 4   wind_direction_10m_dominant_flasjon     1092 non-null   float32       \n",
      " 5   city_flasjon                            1092 non-null   object        \n",
      " 6   temperature_2m_mean_hudiksvall          1092 non-null   float32       \n",
      " 7   precipitation_sum_hudiksvall            1092 non-null   float32       \n",
      " 8   wind_speed_10m_max_hudiksvall           1092 non-null   float32       \n",
      " 9   wind_direction_10m_dominant_hudiksvall  1092 non-null   float32       \n",
      " 10  city_hudiksvall                         1092 non-null   object        \n",
      " 11  temperature_2m_mean_ange                1092 non-null   float32       \n",
      " 12  precipitation_sum_ange                  1092 non-null   float32       \n",
      " 13  wind_speed_10m_max_ange                 1092 non-null   float32       \n",
      " 14  wind_direction_10m_dominant_ange        1092 non-null   float32       \n",
      " 15  city_ange                               1092 non-null   object        \n",
      " 16  temperature_2m_mean_solleftea           1092 non-null   float32       \n",
      " 17  precipitation_sum_solleftea             1092 non-null   float32       \n",
      " 18  wind_speed_10m_max_solleftea            1092 non-null   float32       \n",
      " 19  wind_direction_10m_dominant_solleftea   1092 non-null   float32       \n",
      " 20  city_solleftea                          1092 non-null   object        \n",
      " 21  temperature_2m_mean_umea                1092 non-null   float32       \n",
      " 22  precipitation_sum_umea                  1092 non-null   float32       \n",
      " 23  wind_speed_10m_max_umea                 1092 non-null   float32       \n",
      " 24  wind_direction_10m_dominant_umea        1092 non-null   float32       \n",
      " 25  city_umea                               1092 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(20), object(5)\n",
      "memory usage: 136.6+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5eeb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 10: Define Data Validation Rules </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11bcdcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"sek\", \"min_value\": -5000, \"max_value\": 10000, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"sek\",\n",
    "            \"min_value\":-5000,\n",
    "            \"max_value\":10000,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef9ed3",
   "metadata": {},
   "source": [
    "## Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bff8b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import great_expectations as ge\\nweather_expectation_suite = ge.core.ExpectationSuite(\\n    expectation_suite_name=\"weather_expectation_suite\"\\n)\\n\\ndef expect_greater_than_zero(col):\\n    weather_expectation_suite.add_expectation(\\n        ge.core.ExpectationConfiguration(\\n            expectation_type=\"expect_column_min_to_be_between\",\\n            kwargs={\\n                \"column\":col,\\n                \"min_value\":-0.1,\\n                \"max_value\":1000.0,\\n                \"strict_min\":True\\n            }\\n        )\\n    )\\nexpect_greater_than_zero(\"precipitation_sum\")\\nexpect_greater_than_zero(\"wind_speed_10m_max\")'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3830b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a502",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 11: Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeaf20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 12: Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755b6f",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_price_fg = fs.get_or_create_feature_group(\n",
    "    name=f\"energy_price\",\n",
    "    description='Energy price of each day',\n",
    "    version=1,\n",
    "    primary_key=['zone'],\n",
    "    event_time=\"date\",\n",
    "    stream=True,\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cfa5",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb42574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-27 16:37:08,862 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1290388/fs/1279043/fg/1869353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà| Rows 1089/1089 | Elapsed Time: 00:00 | Remainin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: energy_price_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1290388/jobs/named/energy_price_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('energy_price_1_offline_fg_materialization', 'PYSPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"sek\",\n",
       "           \"min_value\": -5000,\n",
       "           \"max_value\": 10000,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 797739\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": -95.55000305175781,\n",
       "         \"element_count\": 1089,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-12-27T03:37:08.000861Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-12-27T16:37:08.862023+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"e7b62ba4-e339-11f0-a731-0a680915c7cb\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251227T153708.861812Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_price_fg.insert(df_aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1606",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "577effca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x177aebfa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_price_fg.update_feature_description(\"date\", \"Date of measurement of energy price\")\n",
    "energy_price_fg.update_feature_description(\"zone\", \"Zone where measurement are taken\")\n",
    "energy_price_fg.update_feature_description(\"sek\", \"Energy price in SEK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name=f\"weather\",\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    #primary_key=\"date\",\n",
    "    event_time=\"date\",\n",
    "    stream=True,\n",
    "    #expectation_suite=weather_expectation_suite\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721881b7",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba846ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1290388/fs/1279043/fg/1869354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà| Rows 1092/1092 | Elapsed Time: 00:00 | Remainin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1290388/jobs/named/weather_1_offline_fg_materialization/executions\n",
      "2025-12-27 16:32:00,928 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-27 16:32:04,279 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-27 16:34:51,166 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: UNDEFINED\n",
      "2025-12-27 16:34:54,367 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-27 16:34:54,556 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-27 16:35:16,820 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_1_offline_fg_materialization', 'PYSPARK'), None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert data\n",
    "weather_fg.insert(combined_weather_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87422d",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71e6f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x314706260>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6c8fe-c8a4-4947-b50d-bd61f6a0ba9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
