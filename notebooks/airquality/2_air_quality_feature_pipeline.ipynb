{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /Users/alexanderdahm/Documents/GitHub/mlfs-book-proj\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 13:10:19,913 WARNING: DeprecationWarning: 'parseString' deprecated - use 'parse_string'\n",
      "\n",
      "2025-12-28 13:10:19,913 WARNING: DeprecationWarning: 'resetCache' deprecated - use 'reset_cache'\n",
      "\n",
      "2025-12-28 13:10:19,942 WARNING: DeprecationWarning: 'enablePackrat' deprecated - use 'enable_packrat'\n",
      "\n",
      "2025-12-28 13:10:19,957 WARNING: In /Users/alexanderdahm/miniconda3/envs/aq/lib/python3.10/site-packages/matplotlib/mpl-data/stylelib/classic.mplstyle: 'parseString' deprecated - use 'parse_string'\n",
      "2025-12-28 13:10:19,957 WARNING: In /Users/alexanderdahm/miniconda3/envs/aq/lib/python3.10/site-packages/matplotlib/mpl-data/stylelib/classic.mplstyle: 'resetCache' deprecated - use 'reset_cache'\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4589678f-3a0e-4df4-ae17-9ec81d6f9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sensor: sensor0 located at flasjon, flasjon, sweden with coordinates (62.760350390111626, 13.715986496712969), csv path \n",
      "Processing sensor: sensor1 located at hudiksvall, hudiksvall, sweden with coordinates (61.790862930411194, 17.15754858778168), csv path \n",
      "Processing sensor: sensor2 located at ange, ange, sweden with coordinates (62.54989082316923, 15.751547550392734), csv path \n",
      "Processing sensor: sensor3 located at solleftea, solleftea, sweden with coordinates (63.159587742988755, 17.2655114712721), csv path \n",
      "Processing sensor: sensor4 located at umea, umea, sweden with coordinates (63.81702480736613, 20.18691175826482), csv path \n"
     ]
    }
   ],
   "source": [
    "class Sensor:\n",
    "    def __init__(self, name, city, lat, lon, csv=\"\"):\n",
    "        self.name = name\n",
    "        self.country = \"sweden\"\n",
    "        self.city = city\n",
    "        self.street = city\n",
    "        self.url = \"\"  # no explicit AQICN URL provided for these cities\n",
    "        self.lat = float(lat)\n",
    "        self.lon = float(lon)\n",
    "        self.csv = csv\n",
    "\n",
    "cities = [\n",
    "    {\"name\": \"flasjon\", \"lat\": 62.760350390111626, \"lon\": 13.715986496712969},\n",
    "    {\"name\": \"hudiksvall\", \"lat\": 61.790862930411194, \"lon\": 17.15754858778168},\n",
    "    {\"name\": \"ange\", \"lat\": 62.54989082316923, \"lon\": 15.751547550392734},\n",
    "    {\"name\": \"solleftea\", \"lat\": 63.159587742988755, \"lon\": 17.2655114712721},\n",
    "    {\"name\": \"umea\", \"lat\": 63.81702480736613, \"lon\": 20.18691175826482},\n",
    "]\n",
    "\n",
    "sensorList = []\n",
    "for idx, c in enumerate(cities):\n",
    "    sensorList.append(Sensor(f\"sensor{idx}\", c[\"name\"], c[\"lat\"], c[\"lon\"], \"\"))\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "for sensor in sensorList:\n",
    "    print(f\"Processing sensor: {sensor.name} located at {sensor.street}, {sensor.city}, {sensor.country} with coordinates ({sensor.lat}, {sensor.lon}), csv path {sensor.csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 13:10:20,085 INFO: Initializing external client\n",
      "2025-12-28 13:10:20,085 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 13:10:36,710 INFO: Closing external client and cleaning up certificates.\n",
      "2025-12-28 13:10:36,744 INFO: Connection closed.\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1290388/credentials). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":110021,\"usrMsg\":\"Failed to download credentials for projectId: 1290388\",\"devMsg\":\"jakarta.ejb.EJBTransactionRolledbackException: Exception thrown from bean: jakarta.ejb.EJBTransactionRolledbackException: Exception thrown from bean: jakarta.ejb.EJBException: An error has occurred.\",\"errorMsg\":\"Failed to download.\"}', error code: 110021, error msg: Failed to download., user msg: Failed to download credentials for projectId: 1290388",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43mhopsworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m fs \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mget_feature_store() \n\u001b[1;32m      3\u001b[0m secrets \u001b[38;5;241m=\u001b[39m hopsworks\u001b[38;5;241m.\u001b[39mget_secrets_api()\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks/__init__.py:281\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(host, port, project, api_key_value, api_key_file, hostname_verification, trust_store_path, engine)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m hw_e:\n\u001b[1;32m    280\u001b[0m     logout()\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m hw_e\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_e:\n\u001b[1;32m    283\u001b[0m     logout()\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks/__init__.py:278\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(host, port, project, api_key_value, api_key_file, hostname_verification, trust_store_path, engine)\u001b[0m\n\u001b[1;32m    276\u001b[0m     _connected_project \u001b[38;5;241m=\u001b[39m _prompt_project(_hw_connection, project, is_app)\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _connected_project:\n\u001b[0;32m--> 278\u001b[0m         \u001b[43m_set_active_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_connected_project\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m hw_e:\n\u001b[1;32m    280\u001b[0m     logout()\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks/__init__.py:511\u001b[0m, in \u001b[0;36m_set_active_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    509\u001b[0m _client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_instance()\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _client\u001b[38;5;241m.\u001b[39m_is_external():\n\u001b[0;32m--> 511\u001b[0m     \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks_common/client/external.py:104\u001b[0m, in \u001b[0;36mClient.provide_project\u001b[0;34m(self, project)\u001b[0m\n\u001b[1;32m    101\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting Project ID: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_id)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_certs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# When using the Spark engine with metastore connection, the certificates\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# are needed when the application starts (before user code is run)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# So in this case, we can't materialize the certificates on the fly.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning in Spark environment, initializing Spark session\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks_common/client/external.py:170\u001b[0m, in \u001b[0;36mClient.download_certs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_certs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 170\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_materialize_certs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_pem_file(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaChain\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ca_chain_path())\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_pem_file(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclientCert\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_client_cert_path())\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks_common/client/external.py:197\u001b[0m, in \u001b[0;36mClient._materialize_certs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning in Python environment, creating certificates folder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cert_folder_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cert_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 197\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_project_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_b64_cert_to_bytes(\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mstr\u001b[39m(credentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkStore\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m    200\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_jks_key_store_path(),\n\u001b[1;32m    201\u001b[0m )\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_b64_cert_to_bytes(\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(credentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtStore\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m    204\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_jks_trust_store_path(),\n\u001b[1;32m    205\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks_common/client/base.py:114\u001b[0m, in \u001b[0;36mClient._get_credentials\u001b[0;34m(self, project_id)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_credentials\u001b[39m(\u001b[38;5;28mself\u001b[39m, project_id):\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Makes a REST call to hopsworks for getting the project user certificates needed to connect to services such as Hive\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    :param project_id: id of the project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: dict\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcredentials\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks_common/decorators.py:48\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aq/lib/python3.10/site-packages/hopsworks_common/client/base.py:186\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[1;32m    181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    182\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1290388/credentials). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":110021,\"usrMsg\":\"Failed to download credentials for projectId: 1290388\",\"devMsg\":\"jakarta.ejb.EJBTransactionRolledbackException: Exception thrown from bean: jakarta.ejb.EJBTransactionRolledbackException: Exception thrown from bean: jakarta.ejb.EJBException: An error has occurred.\",\"errorMsg\":\"Failed to download.\"}', error code: 110021, error msg: Failed to download., user msg: Failed to download credentials for projectId: 1290388"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\"\"\"location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str\"\"\"\n",
    "today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='energy_price',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167f36e-5a69-424c-9324-fcbebd55febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the historical air quality, so we can use it to get roll3 value of today\n",
    "aq_history = air_quality_fg.read(online=False)[[\"date\", \"pm25\", \"country\", \"city\", \"street\", \"url\"]]\n",
    "aq_history[\"date\"] = pd.to_datetime(aq_history[\"date\"], utc=True).dt.tz_convert(None)\n",
    "\n",
    "# List to store new values\n",
    "aq_rows = []\n",
    "# Collect per-city daily weather dfs to merge into wide format (same as file 1)\n",
    "all_weather_data = []\n",
    "\n",
    "# Loop over each sensor and add their daily data\n",
    "for sensor in sensorList:\n",
    "    country = sensor.country\n",
    "    city = sensor.city\n",
    "    street = sensor.street\n",
    "    aqicn_url = sensor.url\n",
    "    latitude = sensor.lat\n",
    "    longitude = sensor.lon\n",
    "\n",
    "    # Get today air quality\n",
    "    aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"], utc=True).dt.tz_convert(None)\n",
    "\n",
    "    # Filter historical data to this sensor only: Use city and street as unique identifiers.\n",
    "    aq_history_sensor = aq_history[(aq_history[\"city\"] == city) & (aq_history[\"street\"] == street)]\n",
    "\n",
    "    # Concat historic and daily air quality data for a specific sensor\n",
    "    aq_all = pd.concat([aq_history_sensor, aq_today_df], ignore_index=True)\n",
    "    aq_all = aq_all.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # Keep only today's data and drop if nan\n",
    "    aq_today_data = aq_all[aq_all[\"date\"] == aq_today_df[\"date\"].iloc[0]]\n",
    "    if not aq_today_data.empty:\n",
    "        aq_rows.append(aq_today_data)\n",
    "\n",
    "    # Get weather data (daily at ~12:00), then rename columns with city suffix to produce wide format\n",
    "    hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index(\"date\")\n",
    "\n",
    "    # We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "    # We only want the daily weather data, so only get weather at 12:00\n",
    "    daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "    daily_df = daily_df.reset_index()\n",
    "    daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "    daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "    # Rename columns to include city name (exclude 'date')\n",
    "    daily_df = daily_df.rename(columns={col: f\"{col}_{city}\" for col in daily_df.columns if col != \"date\"})\n",
    "    all_weather_data.append(daily_df)\n",
    "\n",
    "# Upload new data to feature store\n",
    "if aq_rows:\n",
    "    aq_insert_df = pd.concat(aq_rows, ignore_index=True)\n",
    "    air_quality_fg.insert(aq_insert_df)\n",
    "\n",
    "if all_weather_data:\n",
    "    combined_weather_df = all_weather_data[0]\n",
    "    for df in all_weather_data[1:]:\n",
    "        combined_weather_df = pd.merge(combined_weather_df, df, on=\"date\", how=\"outer\")\n",
    "    weather_fg.insert(combined_weather_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "190ea7959a836f4799545ea0f3718ade3abee093b15861ffdc25233d6ab7050e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
